{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from math import log, exp"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Acuratetea, precizia, rapelul - clasificare multi-clasa"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Compute the accuracy, precision and recall for a clasification problem.\n",
    "    input:  real_labels - list of all real labels; computed_labes - list of all computed labels;\n",
    "            label_names - list of all class labels\n",
    "    output: the accuracy, precision, recall - all float numbers in (0,1)\n",
    "\"\"\"\n",
    "def evalClassification(real_labels, computed_labels, label_names):\n",
    "\n",
    "    acc = accuracy_score(real_labels, computed_labels)\n",
    "    precision = precision_score(real_labels, computed_labels, average = None, labels = label_names)\n",
    "    recall = recall_score(real_labels, computed_labels, average = None, labels = label_names)\n",
    "    return acc, precision, recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuratete: 0.3076923076923077\n",
      "precizie rose: 0.25\n",
      "rapel rose: 0.25\n",
      "precizie tulip: 0.2857142857142857\n",
      "rapel tulip: 0.2857142857142857\n",
      "precizie daisy: 0.36363636363636365\n",
      "rapel daisy: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "data = read_csv('data/flowers.csv')\n",
    "\n",
    "real_labels = []\n",
    "computed_labels = []\n",
    "for real_label, computed_label in zip(data.Type, data.PredictedType):\n",
    "    real_labels.append(real_label)\n",
    "    computed_labels.append(computed_label)\n",
    "\n",
    "accuracy, precision, recall = evalClassification(real_labels, computed_labels, ['Rose', 'Tulip', 'Daisy'])\n",
    "\n",
    "print('acuratete:', accuracy)\n",
    "print('precizie rose:', precision[0])\n",
    "print('rapel rose:', recall[0])\n",
    "print('precizie tulip:', precision[1])\n",
    "print('rapel tulip:', recall[1])\n",
    "print('precizie daisy:', precision[2])\n",
    "print('rapel daisy:', recall[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross-entropy loss - binary-classification problem"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the cross-entropy loss for a binary-classification problem.\n",
    "    input: real_labels - list of all real labels; computed_outputs - list of tuples of 2 subunitary values with sum = 1\n",
    "    output: cross-entropy loss value\n",
    "\"\"\"\n",
    "def cross_entropy_loss_binary(real_labels, computed_outputs):\n",
    "    real_outputs = [[1, 0] if label == 'spam' else [0, 1] for label in real_labels]\n",
    "    dataset_size = len(real_labels)\n",
    "    no_classes = len(set(real_labels))\n",
    "    dataset_ce = 0.0\n",
    "    for i in range(dataset_size):\n",
    "        sample_ce = - sum([real_outputs[i][j] * log(computed_outputs[i][j]) for j in range(no_classes)])\n",
    "        dataset_ce += sample_ce\n",
    "    mean_ce = dataset_ce / dataset_size\n",
    "    return mean_ce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.6709497382889827\n"
     ]
    }
   ],
   "source": [
    "real_labels =        ['spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam']\n",
    "computed_outputs = [ [0.7, 0.3], [0.2, 0.8], [0.4, 0.6], [0.9, 0.1], [0.7, 0.3], [0.4, 0.6], [0.9, 0.1], [0.2, 0.8], [0.8, 0.2], [0.6, 0.4]]\n",
    "\n",
    "print('CE Loss:', cross_entropy_loss_binary(real_labels, computed_outputs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Softmax cross-entropy loss - multi-class classification problems"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the sigmoid cross-entropy loss for multi-label classification problem\n",
    "    input: real_labels - list of tuples containing binary values, only one being 1; raw_outputs - list of tuples of real values\n",
    "    output: sigmoid cross-entropy value\n",
    "\"\"\"\n",
    "def cross_entropy_loss_multi_class(real_labels, raw_outputs):\n",
    "    ce = 0.0\n",
    "    for i in range(len(real_labels)):\n",
    "        no_classes = len(real_labels[i])\n",
    "        exp_values = [exp(val) for val in raw_outputs[i]]\n",
    "        map_outputs = [val / sum(exp_values) for val in exp_values]\n",
    "        sample_ce = - sum([real_labels[i][j] * log(map_outputs[j]) for j in range(no_classes)])\n",
    "        ce += sample_ce\n",
    "    return ce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax CE: 25.093136536679886\n"
     ]
    }
   ],
   "source": [
    "real_labels = [[1, 0, 0, 0, 0], [0, 1, 0, 0, 0], [1, 0, 0, 0, 0], [0, 0, 1, 0, 0], [1, 0, 0, 0, 0], [0, 0, 0, 0, 1]]\n",
    "raw_outputs = [[10, 1.4, -5.2, 7.6, -4.2], [-2, 6, 3.4, 5, 1], [1.2, 2.2, 1, 5.4, -7.8], [-3, 5, 3, 5, -6], [-2.4, 4, 4.2, 15, -5], [6, 4, -3, 2.3, 7.6]]\n",
    "print('Softmax CE:', cross_entropy_loss_multi_class(real_labels, raw_outputs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sigmoid cross-entropy loss - multi-label classification problems"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the sigmoid cross-entropy loss for multi-label classification problem\n",
    "    input: real_labels - list of tuples containing binary values; raw_outputs - list of tuples of real values\n",
    "    output: sigmoid cross-entropy value\n",
    "\"\"\"\n",
    "def cross_entropy_loss_multi_label(real_labels, raw_outputs):\n",
    "    ce = 0.0\n",
    "    for i in range(len(real_labels)):\n",
    "        no_classes = len(real_labels[i])\n",
    "        map_outputs = [1 / (1 + exp(-val)) for val in raw_outputs[i]]\n",
    "        sample_ce = - sum([real_labels[i][j] * log(map_outputs[j]) for j in range(no_classes)])\n",
    "        ce += sample_ce\n",
    "    return ce"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid CE: 12.702952468404927\n"
     ]
    }
   ],
   "source": [
    "real_labels = [[0, 0, 1, 0, 1], [0, 1, 1, 0, 0], [1, 0, 1, 0, 0], [0, 0, 1, 1, 0], [1, 1, 1, 0, 0], [0, 0, 0, 1, 0]]\n",
    "raw_outputs = [[5, 1.4, -5.2, 7.6, -4.2], [-2, 6, 3.4, 5, 1], [1.2, 2.2, 1, 5.4, -7.8], [-3, 5, 3, 5, -6], [-2.4, 4, 4.2, 15, -5], [6, 4, -3, 2.3, 7.6]]\n",
    "\n",
    "print('Sigmoid CE:', cross_entropy_loss_multi_label(real_labels, raw_outputs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
